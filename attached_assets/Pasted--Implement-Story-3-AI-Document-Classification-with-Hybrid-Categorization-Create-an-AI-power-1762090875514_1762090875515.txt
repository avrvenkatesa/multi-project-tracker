
  Implement Story 3: AI Document Classification with Hybrid Categorization

  Create an AI-powered document classification system that uses a hybrid approach:
  - First checks if document fits predefined base categories
  - If confidence < 0.7, creates a new domain-specific category
  - Stores classifications in database for downstream processing

  ---

  ## PART 1: Database Migration

  **File: migrations/013_document_classifications.sql**

  Create a new migration file:

  ```sql
  -- Story 3: AI Document Classification
  -- Store classification results for uploaded documents

  CREATE TABLE IF NOT EXISTS document_classifications (
    id SERIAL PRIMARY KEY,
    project_id INTEGER NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
    filename VARCHAR(255) NOT NULL,
    category VARCHAR(50) NOT NULL,
    confidence DECIMAL(3,2) NOT NULL,
    reasoning TEXT,
    is_custom_category BOOLEAN DEFAULT FALSE,
    text_length INTEGER,
    classified_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT valid_confidence CHECK (confidence >= 0 AND confidence <= 1)
  );

  -- Indexes for efficient querying
  CREATE INDEX idx_doc_class_project ON document_classifications(project_id);
  CREATE INDEX idx_doc_class_category ON document_classifications(category);
  CREATE INDEX idx_doc_class_custom ON document_classifications(is_custom_category);

  -- Comment
  COMMENT ON TABLE document_classifications IS 'AI-generated document classifications for routing to specialized processors';
  COMMENT ON COLUMN document_classifications.is_custom_category IS 'TRUE if AI created a new category, FALSE if using base
  categories';

  Run the migration:
  psql $DATABASE_URL -f migrations/013_document_classifications.sql

  ---
  PART 2: Document Classifier Service

  File: services/document-classifier.js

  Create a new service module:

  const OpenAI = require('openai');

  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  });

  // Base categories that downstream processors expect
  const BASE_CATEGORIES = [
    'requirements',    // Functional/technical specs, user stories
    'timeline',        // Project schedules, milestones, deadlines
    'resources',       // Team assignments, roles, capacity planning
    'dependencies',    // Technical dependencies, blockers, prerequisites
    'risks',          // Risk registers, mitigation plans
    'architecture',   // System diagrams, technical design docs
    'other'           // Miscellaneous documents
  ];

  /**
   * Classify a document using hybrid AI approach
   * @param {string} text - Document text content
   * @param {string} filename - Document filename
   * @returns {Promise<{category: string, confidence: number, reasoning: string, is_custom_category: boolean}>}
   */
  async function classifyDocument(text, filename) {
    try {
      console.log(`\nğŸ” Classifying document: ${filename}`);
      console.log(`   Text length: ${text.length} characters`);

      // Truncate very long documents to save API costs
      const maxLength = 8000;
      const truncatedText = text.length > maxLength
        ? text.substring(0, maxLength) + '\n\n[... truncated for classification ...]'
        : text;

      const systemPrompt = `You are a document classifier for project management documents.

  Your task is to classify documents using a HYBRID approach:

  1. First, check if the document fits ONE of these base categories:
     - requirements: Functional/technical specs, user stories, specifications
     - timeline: Project schedules, milestones, Gantt charts, project timelines
     - resources: Team assignments, roles, staffing plans, resource allocation
     - dependencies: Technical dependencies, integration requirements, blockers
     - risks: Risk registers, mitigation plans, RAID logs
     - architecture: System designs, technical architecture, diagrams
     - other: General documentation that doesn't fit above categories

  2. If the document fits a base category with HIGH confidence (>0.7), use that category.

  3. If NO base category is a good fit (confidence â‰¤0.7), CREATE a NEW category that accurately describes the document type.

  New categories should be:
  - Lowercase with hyphens (e.g., "migration-procedure", "test-plan", "cost-estimate")
  - Specific and descriptive (1-3 words)
  - Project management or technical domain related

  Respond ONLY with valid JSON in this exact format:
  {
    "category": "category-name",
    "confidence": 0.85,
    "reasoning": "Brief explanation of why this category was chosen",
    "is_new_category": false
  }`;

      const userPrompt = `Filename: ${filename}

  Document content:
  ${truncatedText}`;

      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.3,  // Lower temperature for more consistent classification
        max_tokens: 200,
        response_format: { type: 'json_object' }
      });

      const result = JSON.parse(response.choices[0].message.content);

      console.log(`   âœ… Classification: ${result.category}`);
      console.log(`   ğŸ“Š Confidence: ${result.confidence}`);
      console.log(`   ğŸ†• Custom category: ${result.is_new_category}`);
      console.log(`   ğŸ’­ Reasoning: ${result.reasoning}`);

      return {
        category: result.category.toLowerCase(),
        confidence: parseFloat(result.confidence),
        reasoning: result.reasoning,
        is_custom_category: result.is_new_category || false,
        text_length: text.length
      };

    } catch (error) {
      console.error('âŒ Classification error:', error.message);

      // Fallback to filename-based heuristic
      return fallbackClassification(filename, text);
    }
  }

  /**
   * Fallback classification based on filename heuristics
   */
  function fallbackClassification(filename, text) {
    const lower = filename.toLowerCase();

    const patterns = {
      'timeline': ['timeline', 'schedule', 'gantt', 'milestone', 'deadline'],
      'requirements': ['requirements', 'req', 'spec', 'user-story', 'functional'],
      'resources': ['resource', 'team', 'staff', 'role', 'capacity'],
      'dependencies': ['dependency', 'dependencies', 'integration', 'blocker'],
      'risks': ['risk', 'raid', 'mitigation', 'issue'],
      'architecture': ['architecture', 'design', 'diagram', 'technical', 'system']
    };

    for (const [category, keywords] of Object.entries(patterns)) {
      if (keywords.some(keyword => lower.includes(keyword))) {
        console.log(`   âš ï¸  Using fallback classification: ${category}`);
        return {
          category,
          confidence: 0.6,
          reasoning: `Fallback classification based on filename pattern`,
          is_custom_category: false,
          text_length: text.length
        };
      }
    }

    return {
      category: 'other',
      confidence: 0.5,
      reasoning: 'Could not determine specific category',
      is_custom_category: false,
      text_length: text.length
    };
  }

  module.exports = {
    classifyDocument,
    BASE_CATEGORIES
  };

  ---
  PART 3: Update Server.js

  Find the upload endpoint (around line 9694):
  /api/projects/:projectId/upload-and-generate-standalone

  After the document text extraction loop, add classification:

  // EXISTING CODE: Extract text from documents
  for (const file of req.files) {
    console.log(`   Processing: ${file.originalname} (${file.size} bytes)`);

    const extracted = await documentService.extractTextFromDocument(
      file.buffer,
      file.mimetype,
      file.originalname
    );

    extractedDocuments.push({
      filename: file.originalname,
      text: extracted.text,
      size: file.size,
      mimeType: file.mimetype
    });
  }

  // ADD NEW CODE: Classify each document
  const documentClassifier = require('./services/document-classifier');
  const db = require('./db');

  console.log(`\nğŸ“‹ Classifying ${extractedDocuments.length} documents...`);

  for (const doc of extractedDocuments) {
    const classification = await documentClassifier.classifyDocument(
      doc.text,
      doc.filename
    );

    // Store classification in database
    await db.query(
      `INSERT INTO document_classifications
       (project_id, filename, category, confidence, reasoning, is_custom_category, text_length)
       VALUES ($1, $2, $3, $4, $5, $6, $7)
       RETURNING id`,
      [
        projectId,
        doc.filename,
        classification.category,
        classification.confidence,
        classification.reasoning,
        classification.is_custom_category,
        classification.text_length
      ]
    );

    // Add classification to document object
    doc.classification = {
      category: classification.category,
      confidence: classification.confidence,
      is_custom: classification.is_custom_category
    };
  }

  console.log(`âœ… Classification complete\n`);

  // UPDATE RESPONSE to include classifications
  res.json({
    success: true,
    documentCount: extractedDocuments.length,
    documents: extractedDocuments.map(d => ({
      filename: d.filename,
      textLength: d.text.length,
      size: d.size,
      classification: d.classification
    }))
  });

  ---
  PART 4: Testing

  Test with sample documents:

  1. Requirements document:
    - Upload a file named "Requirements.pdf" or "Functional_Specs.docx"
    - Content: "User Story 1: As a user, I want to login..."
    - Expected: category="requirements", is_custom=false
  2. Timeline document:
    - Upload "Project_Timeline.pdf" or "Gantt_Chart.xlsx"
    - Content: "Phase 1: Jan 1-15, Phase 2: Jan 16-31..."
    - Expected: category="timeline", is_custom=false
  3. Custom category document:
    - Upload "Migration_Cutover_Procedure.docx"
    - Content: "Step 1: Backup AD, Step 2: Run migration script..."
    - Expected: category="migration-procedure" or similar, is_custom=true

  Check results in database:
  SELECT filename, category, confidence, is_custom_category, reasoning
  FROM document_classifications
  WHERE project_id = YOUR_PROJECT_ID
  ORDER BY classified_at DESC;

  Expected console output:
  ğŸ“¤ Multi-document upload for project 123:
     3 files (max: 5)
     Processing: Requirements.pdf (45000 bytes)
     Processing: Timeline.xlsx (12000 bytes)
     Processing: Cutover_Plan.docx (8000 bytes)
  âœ… Extracted 3 documents

  ğŸ“‹ Classifying 3 documents...

  ğŸ” Classifying document: Requirements.pdf
     Text length: 3200 characters
     âœ… Classification: requirements
     ğŸ“Š Confidence: 0.92
     ğŸ†• Custom category: false
     ğŸ’­ Reasoning: Document contains user stories and functional specifications

  ğŸ” Classifying document: Timeline.xlsx
     Text length: 1500 characters
     âœ… Classification: timeline
     ğŸ“Š Confidence: 0.88
     ğŸ†• Custom category: false
     ğŸ’­ Reasoning: Document contains project milestones and dates

  ğŸ” Classifying document: Cutover_Plan.docx
     Text length: 2100 characters
     âœ… Classification: migration-procedure
     ğŸ“Š Confidence: 0.85
     ğŸ†• Custom category: true
     ğŸ’­ Reasoning: Document describes step-by-step migration cutover process

  âœ… Classification complete

  ---
  PART 5: Verification Checklist

  After implementation, verify:

  - Migration creates document_classifications table
  - Table has no category constraint (allows dynamic categories)
  - services/document-classifier.js exports classifyDocument function
  - AI uses GPT-4o model
  - AI tries base categories first
  - AI creates custom categories when confidence < 0.7
  - Fallback heuristics work if API fails
  - Upload endpoint calls classifier for each document
  - Classifications stored in database
  - Response includes classification results
  - Console logs show classification details
  - Test with 3+ different document types